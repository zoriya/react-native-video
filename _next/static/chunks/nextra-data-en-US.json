{"/component/ads":{"title":"Ads","data":{"ima-sdk#IMA SDK":"react-native-video has built-in support for Google IMA SDK for Android and iOS. To enable it please refer to installation section","usage#Usage":"To use AVOD, you need to pass adTagUrl prop to Video component. adTagUrl is a VAST uri.Example:\nadTagUrl=\"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpremidpostoptimizedpodbumper&ciu_szs=300x250&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&cmsid=496&vid=short_onecue&correlator=\"\nNOTE: Video ads cannot start when you are using the PIP on iOS (more info available at Google IMA SDK Docs). If you are using custom controls, you must hide your PIP button when you receive the STARTED event from onReceiveAdEvent and show it again when you receive the ALL_ADS_COMPLETED event.","events#Events":"To receive events from IMA SDK, you need to pass onReceiveAdEvent prop to Video component. List of events, you can find hereExample:\n...\nonReceiveAdEvent={event => console.log(event)}\n..."}},"/component/drm":{"title":"DRM","data":{"":"Note: DRM is not supported on visionOS yet.","provide-drm-data-only-tested-with-httphttps-assets#Provide DRM data (only tested with http/https assets)":"You can provide some configuration to allow DRM playback.\nThis feature will disable the use of TextureView on Android.DRM object allows this members:","base64certificate#base64Certificate":"Type: bool\nDefault: falseWhether or not the certificate url returns it on base64.","certificateurl#certificateUrl":"Type: string\nDefault: undefinedURL to fetch a valid certificate for FairPlay.","getlicense#getLicense":"Type: function\nDefault: undefinedRather than setting the licenseServer url to get the license, you can manually get the license on the JS part, and send the result to the native part to configure FairplayDRM for the streamlicenseServer and headers will be ignored. You will obtain as argument the SPC\n(as ASCII string, you will probably need to convert it to base 64) obtained from\nyour contentId + the provided certificate via objc [loadingRequest streamingContentKeyRequestDataForApp:certificateData\ncontentIdentifier:contentIdData options:nil error:&spcError]; Also, you will receive following parameter of getLicense:\ncontentId contentId if passed to drm object or loadingRequest.request.url?.host\nloadedLicenseUrl URL defined as loadingRequest.request.URL.absoluteString, this url starts with skd:// or clearkey://\nlicenseServer prop if prop is passed to drm object.\nspcString the SPC used to validate playback with drm server\nYou should return on this method a CKC in Base64, either by just returning it or returning a Promise that resolves with the CKC.With this prop you can override the license acquisition flow, as an example:\ngetLicense: (spcString, contentId, licenseUrl, loadedLicenseUrl) => {\n  const base64spc = Base64.encode(spcString);\n  const formData = new FormData();\n  formData.append('spc', base64spc);\n  return fetch(`https://license.pallycon.com/ri/licenseManager.do`, {\n    method: 'POST',\n    headers: {\n      'pallycon-customdata-v2':\n        '==',\n      'Content-Type': 'application/x-www-form-urlencoded',\n    },\n    body: formData,\n  })\n    .then((response) => response.text())\n    .then((response) => {\n      return response;\n    })\n    .catch((error) => {\n      console.error('Error', error);\n    });\n};","headers#headers":"Type: Object\nDefault: undefinedYou can customize headers send to the licenseServer.Example:\nsource={{\n    uri: 'https://media.axprod.net/TestVectors/v7-MultiDRM-SingleKey/Manifest_1080p.mpd',\n}}\ndrm={{\n      type: DRMType.WIDEVINE,\n      licenseServer: 'https://drm-widevine-licensing.axtest.net/AcquireLicense',\n      headers: {\n          'X-AxDRM-Message': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..FAbIiPxX8BHi9RwfzD7Yn-wugU19ghrkBFKsaCPrZmU'\n      },\n}}","licenseserver#licenseServer":"Type: string\nDefault: falseThe URL pointing to the licenseServer that will provide the authorization to play the protected stream.","type#type":"Type: DRMType\nDefault: undefinedYou can specify the DRM type, either by string or using the exported DRMType enum.\nValid values are, for Android: DRMType.WIDEVINE / DRMType.PLAYREADY / DRMType.CLEARKEY.\nfor iOS: DRMType.FAIRPLAY","contentid#contentId":"Type: string\nDefault: undefinedSpecify the content id of the stream, otherwise it will take the host value from loadingRequest.request.URL.host (f.e: skd://testAsset -> will take testAsset)","common-usage-scenarios#Common Usage Scenarios":"","send-cookies-to-license-server#Send cookies to license server":"You can send Cookies to the license server via headers prop. Example:\ndrm: {\n    type: DRMType.WIDEVINE\n    licenseServer: 'https://drm-widevine-licensing.axtest.net/AcquireLicense',\n    headers: {\n        'Cookie': 'PHPSESSID=etcetc; csrftoken=mytoken; _gat=1; foo=bar'\n    },\n}","custom-license-acquisition-only-ios-for-now#Custom License Acquisition (only iOS for now)":"drm: {\n    type: DRMType.FAIRPLAY,\n    getLicense: (spcString) => {\n        const base64spc = Base64.encode(spcString);\n        return fetch('YOUR LICENSE SERVER HERE', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n                Accept: 'application/json',\n            },\n            body: JSON.stringify({\n                getFairplayLicense: {\n                    foo: 'bar',\n                    spcMessage: base64spc,\n                }\n            })\n        })\n            .then(response => response.json())\n            .then((response) => {\n                if (response && response.getFairplayLicenseResponse\n                    && response.getFairplayLicenseResponse.ckcResponse) {\n                    return response.getFairplayLicenseResponse.ckcResponse;\n                }\n                throw new Error('No correct response');\n            })\n            .catch((error) => {\n                console.error('CKC error', error);\n            });\n    }\n}"}},"/component/events":{"title":"Events","data":{"":"This page shows the list of available callbacks to handle player notifications","details#Details":"","onaudiobecomingnoisy#onAudioBecomingNoisy":"Callback function that is called when the audio is about to become 'noisy' due to\na change in audio outputs. Typically this is called when audio output is being switched\nfrom an external source like headphones back to the internal speaker. It's a good\nidea to pause the media when this happens so the speaker doesn't start blasting sound.Payload: none","onaudiofocuschanged#onAudioFocusChanged":"Callback function that is called when the audio focus changes. This is called when the audio focus is gained or lost. This is useful for determining if the media should be paused or not.Payload:\nProperty\tType\tDescription\thasAudioFocus\tboolean\tBoolean indicating whether the media has audio focus\t\nExample:\n{\n  hasAudioFocus: true;\n}","onaudiotracks#onAudioTracks":"Callback function that is called when audio tracks changePayload:An array of\nProperty\tType\tDescription\tindex\tnumber\tIndex number of the track\ttitle\tstring\tDescription of the track\tlanguage\tstring\t2 letter ISO 639-1 or 3 letter ISO 639-2 language code\ttype\tstring\tMime type of track\t\nExample:\n{\n  audioTracks: [\n    {language: 'es', title: 'Spanish', type: 'audio/mpeg', index: 0},\n    {language: 'en', title: 'English', type: 'audio/mpeg', index: 1},\n  ];\n}","onbandwidthupdate#onBandwidthUpdate":"Callback function that is called when the available bandwidth changes.Payload:\nProperty\tType\tDescription\tbitrate\tnumber\tThe estimated bitrate in bits/sec\twidth\tnumber\tThe width of the video (android only)\theight\tnumber\tThe height of the video (android only)\ttrackId\tstring\tThe track ID of the video track (android only)\t\nExample on iOS:\n{\n  bitrate: 1000000;\n}\nExample on Android:\n{\n  bitrate: 1000000;\n  width: 1920;\n  height: 1080;\n  trackId: 'some-track-id';\n}\nNote: On Android, you must set the reportBandwidth prop to enable this event. This is due to the high volume of events generated.","onbuffer#onBuffer":"Callback function that is called when the player buffers.Payload:\nProperty\tType\tDescription\tisBuffering\tboolean\tBoolean indicating whether buffering is active\t\nExample:\n{\n  isBuffering: true;\n}","onend#onEnd":"Callback function that is called when the player reaches the end of the media.Payload: none","onerror#onError":"Callback function that is called when the player experiences a playback error.Payload:\nProperty\tType\tDescription\terror\tobject\tObject containing properties with information about the error","onexternalplaybackchange#onExternalPlaybackChange":"Callback function that is called when external playback mode for current playing video has changed. Mostly useful when connecting/disconnecting to Apple TV – it's called on connection/disconnection.Payload:\nProperty\tType\tDescription\tisExternalPlaybackActive\tboolean\tBoolean indicating whether external playback mode is active\t\nExample:\n{\n  isExternalPlaybackActive: true;\n}","onfullscreenplayerwillpresent#onFullscreenPlayerWillPresent":"Callback function that is called when the player is about to enter fullscreen mode.Payload: none","onfullscreenplayerdidpresent#onFullscreenPlayerDidPresent":"Callback function that is called when the player has entered fullscreen mode.Payload: none","onfullscreenplayerwilldismiss#onFullscreenPlayerWillDismiss":"Callback function that is called when the player is about to exit fullscreen mode.Payload: none","onfullscreenplayerdiddismiss#onFullscreenPlayerDidDismiss":"Callback function that is called when the player has exited fullscreen mode.Payload: none","onload#onLoad":"Callback function that is called when the media is loaded and ready to play.Payload:\nProperty\tType\tDescription\tcurrentTime\tnumber\tTime in seconds where the media will start\tduration\tnumber\tLength of the media in seconds\tnaturalSize\tobject\tProperties: _ width - Width in pixels that the video was encoded at _ height - Height in pixels that the video was encoded at * orientation - \"portrait\" or \"landscape\"\taudioTracks\tarray\tAn array of audio track info objects with the following properties: _ index - Index number _ title - Description of the track _ language - 2 letter ISO 639-1 or 3 letter ISO639-2 language code _ type - Mime type of track\ttextTracks\tarray\tAn array of text track info objects with the following properties: _ index - Index number _ title - Description of the track _ language - 2 letter ISO 639-1 or 3 letter ISO 639-2 language code _ type - Mime type of track\tvideoTracks\tarray\tAn array of video track info objects with the following properties: _ trackId - ID for the track _ bitrate - Bit rate in bits per second _ codecs - Comma separated list of codecs _ height - Height of the video * width - Width of the video\t\nExample:\n{\n  canPlaySlowForward: true,\n  canPlayReverse: false,\n  canPlaySlowReverse: false,\n  canPlayFastForward: false,\n  canStepForward: false,\n  canStepBackward: false,\n  currentTime: 0,\n  duration: 5910.208984375,\n  naturalSize: {\n     height: 1080\n     orientation: 'landscape'\n     width: '1920'\n  },\n  audioTracks: [\n    { language: 'es', title: 'Spanish', type: 'audio/mpeg', index: 0 },\n    { language: 'en', title: 'English', type: 'audio/mpeg', index: 1 }\n  ],\n  textTracks: [\n    { title: '#1 French', language: 'fr', index: 0, type: 'text/vtt' },\n    { title: '#2 English CC', language: 'en', index: 1, type: 'text/vtt' },\n    { title: '#3 English Director Commentary', language: 'en', index: 2, type: 'text/vtt' }\n  ],\n  videoTracks: [\n    { bitrate: 3987904, codecs: \"avc1.640028\", height: 720, trackId: \"f1-v1-x3\", width: 1280 },\n    { bitrate: 7981888, codecs: \"avc1.640028\", height: 1080, trackId: \"f2-v1-x3\", width: 1920 },\n    { bitrate: 1994979, codecs: \"avc1.4d401f\", height: 480, trackId: \"f3-v1-x3\", width: 848 }\n  ]\n}","onloadstart#onLoadStart":"Callback function that is called when the media starts loading.Payload:| Property  | Description |\n| --------- | ----------- | ---------------------------------------------------------------- |\n| isNetwork | boolean     | Boolean indicating if the media is being loaded from the network |\n| type      | string      | Type of the media. Not available on Windows                      |\n| uri       | string      | URI for the media source. Not available on Windows               |Example:\n{\n  isNetwork: true,\n  type: '',\n  uri: 'https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8'\n}","onplaybackstatechanged#onPlaybackStateChanged":"Callback function that is called when the playback state changes.Payload:| Property  | Description |\n| --------- | ----------- | ------------------------------------------------- |\n| isPlaying | boolean     | Boolean indicating if the media is playing or not |Example:\n{\n  isPlaying: true,\n}","onpictureinpicturestatuschanged#onPictureInPictureStatusChanged":"Callback function that is called when picture in picture becomes active or inactive.\nProperty\tType\tDescription\tisActive\tboolean\tBoolean indicating whether picture in picture is active\t\nExample:\n{\n  isActive: true;\n}","onplaybackratechange#onPlaybackRateChange":"Callback function that is called when the rate of playback changes - either paused or starts/resumes.\nProperty\tType\tDescription\tplaybackRate\tnumber\t0 when playback is paused, 1 when playing at normal speed. Other values when playback is slowed down or sped up\t\nExample:\n{\n  playbackRate: 0, // indicates paused\n}","onprogress#onProgress":"Callback function that is called every progressUpdateInterval milliseconds with info about which position the media is currently playing.\nProperty\tType\tDescription\tcurrentTime\tnumber\tCurrent position in seconds\tplayableDuration\tnumber\tPosition to where the media can be played to using just the buffer in seconds\tseekableDuration\tnumber\tPosition to where the media can be seeked to in seconds. Typically, the total length of the media\t\nExample:\n{\n  currentTime: 5.2,\n  playableDuration: 34.6,\n  seekableDuration: 888\n}","onreadyfordisplay#onReadyForDisplay":"Callback function that is called when the first video frame is ready for display. This is when the poster is removed.Payload: none\niOS: readyForDisplay\nAndroid STATE_READY","onreceiveadevent#onReceiveAdEvent":"Callback function that is called when an AdEvent is received from the IMA's SDK.Enum AdEvent possible values for Android and iOS:\nEvents\nEvent\tPlatform\tDescription\tAD_BREAK_ENDED\tiOS\tFired the first time each ad break ends. Applications must reenable seeking when this occurs (only used for dynamic ad insertion).\tAD_BREAK_READY\tAndroid, iOS\tFires when an ad rule or a VMAP ad break would have played if autoPlayAdBreaks is false.\tAD_BREAK_STARTED\tiOS\tFired first time each ad break begins playback. If an ad break is watched subsequent times this will not be fired. Applications must disable seeking when this occurs (only used for dynamic ad insertion).\tAD_BUFFERING\tAndroid\tFires when the ad has stalled playback to buffer.\tAD_CAN_PLAY\tAndroid\tFires when the ad is ready to play without buffering, either at the beginning of the ad or after buffering completes.\tAD_METADATA\tAndroid\tFires when an ads list is loaded.\tAD_PERIOD_ENDED\tiOS\tFired every time the stream switches from advertising or slate to content. This will be fired even when an ad is played a second time or when seeking into an ad (only used for dynamic ad insertion).\tAD_PERIOD_STARTED\tiOS\tFired every time the stream switches from content to advertising or slate. This will be fired even when an ad is played a second time or when seeking into an ad (only used for dynamic ad insertion).\tAD_PROGRESS\tAndroid\tFires when the ad's current time value changes. The event data will be populated with an AdProgressData object.\tALL_ADS_COMPLETED\tAndroid, iOS\tFires when the ads manager is done playing all the valid ads in the ads response, or when the response doesn't return any valid ads.\tCLICK\tAndroid, iOS\tFires when the ad is clicked.\tCOMPLETED\tAndroid, iOS\tFires when the ad completes playing.\tCONTENT_PAUSE_REQUESTED\tAndroid\tFires when content should be paused. This usually happens right before an ad is about to cover the content.\tCONTENT_RESUME_REQUESTED\tAndroid\tFires when content should be resumed. This usually happens when an ad finishes or collapses.\tCUEPOINTS_CHANGED\tiOS\tCuepoints changed for VOD stream (only used for dynamic ad insertion).\tDURATION_CHANGE\tAndroid\tFires when the ad's duration changes.\tERROR\tAndroid, iOS\tFires when an error occurred while loading the ad and prevent it from playing.\tFIRST_QUARTILE\tAndroid, iOS\tFires when the ad playhead crosses first quartile.\tIMPRESSION\tAndroid\tFires when the impression URL has been pinged.\tINTERACTION\tAndroid\tFires when an ad triggers the interaction callback. Ad interactions contain an interaction ID string in the ad data.\tLINEAR_CHANGED\tAndroid\tFires when the displayed ad changes from linear to nonlinear, or the reverse.\tLOADED\tAndroid, iOS\tFires when ad data is available.\tLOG\tAndroid, iOS\tFires when a non-fatal error is encountered. The user need not take any action since the SDK will continue with the same or next ad playback depending on the error situation.\tMIDPOINT\tAndroid, iOS\tFires when the ad playhead crosses midpoint.\tPAUSED\tAndroid, iOS\tFires when the ad is paused.\tRESUMED\tAndroid, iOS\tFires when the ad is resumed.\tSKIPPABLE_STATE_CHANGED\tAndroid\tFires when the displayed ads skippable state is changed.\tSKIPPED\tAndroid, iOS\tFires when the ad is skipped by the user.\tSTARTED\tAndroid, iOS\tFires when the ad starts playing.\tSTREAM_LOADED\tiOS\tStream request has loaded (only used for dynamic ad insertion).\tTAPPED\tiOS\tFires when the ad is tapped.\tTHIRD_QUARTILE\tAndroid, iOS\tFires when the ad playhead crosses third quartile.\tUNKNOWN\tiOS\tAn unknown event has fired\tUSER_CLOSE\tAndroid\tFires when the ad is closed by the user.\tVIDEO_CLICKED\tAndroid\tFires when the non-clickthrough portion of a video ad is clicked.\tVIDEO_ICON_CLICKED\tAndroid\tFires when a user clicks a video icon.\tVOLUME_CHANGED\tAndroid\tFires when the ad volume has changed.\tVOLUME_MUTED\tAndroid\tFires when the ad volume has been muted.\t\nPayload:\nProperty\tType\tDescription\tevent\tAdEvent\tThe ad event received\tdata\tRecord<string, string> | undefined\tThe ad event data\t\nExample:\n{\n  \"data\": {\n    \"key\": \"value\"\n  },\n  \"event\": \"LOG\"\n}","onrestoreuserinterfaceforpictureinpicturestop#onRestoreUserInterfaceForPictureInPictureStop":"Callback function that corresponds to Apple's . Call  inside of this function when done restoring the user interface.Payload: none","onseek#onSeek":"Callback function that is called when a seek completes.Payload:\nProperty\tType\tDescription\tcurrentTime\tnumber\tThe current time after the seek\tseekTime\tnumber\tThe requested time\t\nExample:\n{\n  currentTime: 100.5;\n  seekTime: 100;\n}\nBoth the currentTime & seekTime are reported because the video player may not seek to the exact requested position in order to improve seek performance.","ontimedmetadata#onTimedMetadata":"Callback function that is called when timed metadata becomes availablePayload:\nProperty\tType\tDescription\tmetadata\tarray\tArray of metadata objects\t\nExample:\n{\n  metadata: [\n    {value: 'Streaming Encoder', identifier: 'TRSN'},\n    {value: 'Internet Stream', identifier: 'TRSO'},\n    {value: 'Any Time You Like', identifier: 'TIT2'},\n  ];\n}","ontexttracks#onTextTracks":"Callback function that is called when text tracks changePayload:\nProperty\tType\tDescription\tindex\tnumber\tInternal track ID\ttitle\tstring\tDescriptive name for the track\tlanguage\tstring\t2 letter ISO 639-1 code representing the language\ttype\tstring\tMime type of the track _ TextTrackType.SRT - SubRip (.srt) _ TextTrackType.TTML - TTML (.ttml) * TextTrackType.VTT - WebVTT (.vtt)iOS only supports VTT, Android supports all 3\tselected\tboolean\ttrue if track is playing\t\nExample:\n{\n  textTracks: [\n    {\n      index: 0,\n      title: 'Any Time You Like',\n      type: 'srt',\n      selected: true,\n    },\n  ];\n}","ontexttrackdatachanged#onTextTrackDataChanged":"Callback function that is called when new subtitle data is available. It provides the actual subtitle content for the current selected text track, if available (mainly WebVTT).Payload:\nProperty\tType\tDescription\tsubtitleTracks\tstring\tThe subtitles text content in a compatible format.\t\nExample:\n{\n  subtitleTracks: \"This blade has a dark past.\",\n}\nFor details on how to control the visibility of subtitles, see the subtitleStyle section.","onvideotracks#onVideoTracks":"Callback function that is called when video tracks changePayload:\nProperty\tType\tDescription\ttrackId\tnumber\tInternal track ID\tcodecs\tstring\tMimeType of codec used for this track\twidth\tnumber\tTrack width\theight\tnumber\tTrack height\tbitrate\tnumber\tBitrate in bps\tselected\tboolean\ttrue if track is selected for playing\t\nExample:\n{\n  videoTracks: [\n    {\n      trackId: 0,\n      codecs: 'video/mp4',\n      width: 1920,\n      height: 1080,\n      bitrate: 10000,\n      selected: true,\n    },\n  ];\n}","onvolumechange#onVolumeChange":"Callback function that is called when the volume of player changes.\nNote: This event applies to the volume of the player, not the volume of the device.\nPayload:\nProperty\tType\tDescription\tvolume\tnumber\tThe volume of the player (between 0 and 1)\t\nExample:\n{\n  volume: 0.5;\n}"}},"/component/methods":{"title":"Methods","data":{"":"This page shows the list of available methods","dismissfullscreenplayer#dismissFullscreenPlayer":"dismissFullscreenPlayer(): Promise<void>Take the player out of fullscreen mode.","presentfullscreenplayer#presentFullscreenPlayer":"presentFullscreenPlayer(): Promise<void>Put the player in fullscreen mode.On iOS, this displays the video in a fullscreen view controller with controls.On Android, this puts the navigation controls in fullscreen mode. It is not a complete fullscreen implementation, so you will still need to apply a style that makes the width and height match your screen dimensions to get a fullscreen video.","pause#pause":"pause(): Promise<void>Pause the video.","resume#resume":"resume(): Promise<void>Resume the video.","save#save":"save(): Promise<{ uri: string }>Save video to your Photos with current filter prop. Returns promise.Notes:\nCurrently only supports highest quality export\nCurrently only supports MP4 export\nCurrently only supports exporting to user's cache directory with a generated UUID filename.\nUser will need to remove the saved video through their Photos app\nWorks with cached videos as well. (Checkout video-caching example)\nIf the video is has not began buffering (e.g. there is no internet connection) then the save function will throw an error.\nIf the video is buffering then the save function promise will return after the video has finished buffering and processing.\nFuture:\nWill support multiple qualities through options\nWill support more formats in the future through options\nWill support custom directory and file name through options","restoreuserinterfaceforpictureinpicturestopcompleted#restoreUserInterfaceForPictureInPictureStopCompleted":"(restored)This function corresponds to the completion handler in Apple's restoreUserInterfaceForPictureInPictureStop. IMPORTANT: This function must be called after onRestoreUserInterfaceForPictureInPictureStop is called.","seek#seek":"seek(seconds)Seek to the specified position represented by seconds. seconds is a float value.seek() can only be called after the onLoad event has fired. Once completed, the onSeek event will be called.","exact-seek#Exact seek":"By default iOS seeks within 100 milliseconds of the target position. If you need more accuracy, you can use the seek with tolerance method:seek(seconds, tolerance)tolerance is the max distance in milliseconds from the seconds position that's allowed. Using a more exact tolerance can cause seeks to take longer. If you want to seek exactly, set tolerance to 0.","example-usage#Example Usage":"const videoRef = useRef<VideoRef>(null);\nconst someCoolFunctions = async () => {\n  if (!videoRef.current) {\n    return;\n  }\n  // present or dismiss fullscreen player\n  videoRef.current.presentFullscreenPlayer();\n  videoRef.current.dismissFullscreenPlayer();\n  // pause or play the video\n  videoRef.current.play();\n  videoRef.current.pause();\n  // save video to your Photos with current filter prop\n  const response = await videoRef.current.save();\n  const path = response.uri;\n  // seek to the specified position represented by seconds\n  videoRef.current.seek(200);\n  // or on iOS you can seek with tolerance\n  videoRef.current.seek(200, 10);\n};\nreturn (\n  <Video\n    ref={videoRef}\n    source={{uri: 'https://www.w3schools.com/html/mov_bbb.mp4'}}\n  />\n);","static-methods#Static methods":"","getwidevinelevel#getWidevineLevel":"Indicates whether the widevine level supported by device.Possible values are:\n0 - unable to determine widevine support (typically not supported)\n1, 2, 3 - Widevine level supported","iscodecsupported#isCodecSupported":"Indicates whether the provided codec is supported level supported by device.parameters:\nmimetype: mime type of codec to query\nwidth, height: resolution to query\nPossible results:\nhardware - codec is supported by hardware\nsoftware - codec is supported by software only\nunsupported - codec is not supported","ishevcsupported#isHEVCSupported":"Helper which Indicates whether the provided HEVC/1920*1080 is supported level supported by device. It uses isCodecSupported internally.","example-usage-1#Example Usage":"import { VideoDecoderProperties } from 'react-native-video';\nVideoDecoderProperties.getWidevineLevel().then((level) => {\n  ...\n});\nVideoDecoderProperties.isCodecSupported('video/hevc', 1920, 1080).then((support) => {\n  ...\n});\nVideoDecoderProperties.isHEVCSupported().then((support) => {\n  ...\n});"}},"/component/props":{"title":"Configurable props","data":{"":"This page shows the list of available properties to configure player","details#Details":"","adtagurl#adTagUrl":"Sets the VAST uri to play AVOD ads.Example:\nadTagUrl=\"https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/vmap_ad_samples&sz=640x480&cust_params=sample_ar%3Dpremidpostoptimizedpodbumper&ciu_szs=300x250&gdfp_req=1&ad_rule=1&output=vmap&unviewed_position_start=1&env=vp&impl=s&cmsid=496&vid=short_onecue&correlator=\"\nNote: You need enable IMA SDK in gradle or pod file - enable client side ads insertion","allowsexternalplayback#allowsExternalPlayback":"Indicates whether the player allows switching to external playback mode such as AirPlay or HDMI.\ntrue (default) - allow switching to external playback mode\nfalse - Don't allow switching to external playback mode","audioonly#audioOnly":"Indicates whether the player should only play the audio track and instead of displaying the video track, show the poster instead.\nfalse (default) - Display the video as normal\ntrue - Show the poster and play the audio\nFor this to work, the poster prop must be set.","audiooutput#audioOutput":"Changes the audio output.\nspeaker (default) - plays through speaker\nearpiece - plays through earpiece","automaticallywaitstominimizestalling#automaticallyWaitsToMinimizeStalling":"A Boolean value that indicates whether the player should automatically delay playback in order to minimize stalling. For clients linked against iOS 10.0 and later\nfalse - Immediately starts playback\ntrue (default) - Delays playback in order to minimize stalling","backbufferdurationms#backBufferDurationMs":"The number of milliseconds of buffer to keep before the current position. This allows rewinding without rebuffering within that duration.","bufferconfig#bufferConfig":"Adjust the buffer settings. This prop takes an object with one or more of the properties listed below.\nProperty\tType\tDescription\tminBufferMs\tnumber\tThe default minimum duration of media that the player will attempt to ensure is buffered at all times, in milliseconds.\tmaxBufferMs\tnumber\tThe default maximum duration of media that the player will attempt to buffer, in milliseconds.\tbufferForPlaybackMs\tnumber\tThe default duration of media that must be buffered for playback to start or resume following a user action such as a seek, in milliseconds.\tbufferForPlaybackAfterRebufferMs\tnumber\tThe default duration of media that must be buffered for playback to resume after a rebuffer, in milliseconds. A rebuffer is defined to be caused by buffer depletion rather than a user action.\tmaxHeapAllocationPercent\tnumber\tThe percentage of available heap that the video can use to buffer, between 0 and 1\tminBackBufferMemoryReservePercent\tnumber\tThe percentage of available app memory at which during startup the back buffer will be disabled, between 0 and 1\tminBufferMemoryReservePercent\tnumber\tThe percentage of available app memory to keep in reserve that prevents buffer from using it, between 0 and 1\t\nThis prop should only be set when you are setting the source, changing it after the media is loaded will cause it to be reloaded.Example with default values:\nbufferConfig={{\n  minBufferMs: 15000,\n  maxBufferMs: 50000,\n  bufferForPlaybackMs: 2500,\n  bufferForPlaybackAfterRebufferMs: 5000\n}}","chapters#chapters":"To provide a custom chapter source for tvOS. This prop takes an array of objects with the properties listed below.\nProperty\tType\tDescription\ttitle\tstring\tThe title of the chapter to create\tstartTime\tnumber\tThe start time of the chapter in seconds\tendTime\tnumber\tThe end time of the chapter in seconds\turi\tstring?\tOptional: Provide an http orl or the some base64 string to override the image of the chapter. For some media files the images are generated automatically","currentplaybacktime#currentPlaybackTime":"When playing an HLS live stream with a EXT-X-PROGRAM-DATE-TIME tag configured, then this property will contain the epoch value in msec.","controls#controls":"Determines whether to show player controls.\nfalse (default) - Don't show player controls\ntrue - Show player controls\nNote on iOS, controls are always shown when in fullscreen mode.\nNote on Android, native controls are available by default.\nIf needed, you can also add your controls or use a package like react-native-video-controls or react-native-media-console, see Useful Side Project.","contentstarttime#contentStartTime":"The start time in ms for SSAI content. This determines at what time to load the video info like resolutions. Use this only when you have SSAI stream where ads resolution is not the same as content resolution.","debug#debug":"Enable more verbosity in logs.\n[!WARNING]\nDo not use this open in production build\nProperty\tType\tDescription\tenable\tboolean\twhen true, display logs with verbosity higher\tthread\tboolean\tenable thread display\t\nExample with default values:\ndebug={{\n  enable: true,\n  thread: true,\n}}","disablefocus#disableFocus":"Determines whether video audio should override background music/audio in Android devices.\nfalse (default) - Override background audio/music\ntrue - Let background audio/music from other apps play\nNote: Allows multiple videos to play if set to true. If false, when one video is playing and another is started, the first video will be paused.","disabledisconnecterror#disableDisconnectError":"Determines if the player needs to throw an error when connection is lost or not\nfalse (default) - Player will throw an error when connection is lost\ntrue - Player will keep trying to buffer when network connect is lost","drm#DRM":"To setup DRM please follow this guide\n⚠️ DRM is not supported on visionOS yet","filter#filter":"Add video filter\nFilterType.NONE (default) - No Filter\nFilterType.INVERT - CIColorInvert\nFilterType.MONOCHROME - CIColorMonochrome\nFilterType.POSTERIZE - CIColorPosterize\nFilterType.FALSE - CIFalseColor\nFilterType.MAXIMUMCOMPONENT - CIMaximumComponent\nFilterType.MINIMUMCOMPONENT - CIMinimumComponent\nFilterType.CHROME - CIPhotoEffectChrome\nFilterType.FADE - CIPhotoEffectFade\nFilterType.INSTANT - CIPhotoEffectInstant\nFilterType.MONO - CIPhotoEffectMono\nFilterType.NOIR - CIPhotoEffectNoir\nFilterType.PROCESS - CIPhotoEffectProcess\nFilterType.TONAL - CIPhotoEffectTonal\nFilterType.TRANSFER - CIPhotoEffectTransfer\nFilterType.SEPIA - CISepiaTone\nFor more details on these filters refer to the iOS docs.Notes:\nUsing a filter can impact CPU usage. A workaround is to save the video with the filter and then load the saved video.\nVideo filter is currently not supported on HLS playlists.\nfilterEnabled must be set to true","filterenabled#filterEnabled":"Enable video filter.\nfalse (default) - Don't enable filter\ntrue - Enable filter","focusable#Focusable":"Whether this video view should be focusable with a non-touch input device, eg. receive focus with a hardware keyboard.\nfalse - Makes view unfocusable\ntrue (default) - Makes view focusable","fullscreen#fullscreen":"Controls whether the player enters fullscreen on play.\nSee presentFullscreenPlayer for details.\nfalse (default) - Don't display the video in fullscreen\ntrue - Display the video in fullscreen","fullscreenautorotate#fullscreenAutorotate":"If a preferred fullscreenOrientation is set, causes the video to rotate to that orientation but permits rotation of the screen to orientation held by user. Defaults to TRUE.","fullscreenorientation#fullscreenOrientation":"all (default) -\nlandscape\nportrait","headers#headers":"Pass headers to the HTTP client. Can be used for authorization. Headers must be a\npart of the source object.Example:\nsource={{\n  uri: \"https://www.example.com/video.mp4\",\n  headers: {\n    Authorization: 'bearer some-token-value',\n    'X-Custom-Header': 'some value'\n  }\n}}","hideshutterview#hideShutterView":"Controls whether the ExoPlayer shutter view (black screen while loading) is enabled.\nfalse (default) - Show shutter view\ntrue - Hide shutter view","ignoresilentswitch#ignoreSilentSwitch":"Controls the iOS silent switch behavior\n\"inherit\" (default) - Use the default AVPlayer behavior\n\"ignore\" - Play audio even if the silent switch is set\n\"obey\" - Don't play audio if the silent switch is set","maxbitrate#maxBitRate":"Sets the desired limit, in bits per second, of network bandwidth consumption when multiple video streams are available for a playlist.Default: 0. Don't limit the maxBitRate.Example:\nmaxBitRate={2000000} // 2 megabits","minloadretrycount#minLoadRetryCount":"Sets the minimum number of times to retry loading data before failing and reporting an error to the application. Useful to recover from transient internet failures.Default: 3. Retry 3 times.Example:\nminLoadRetryCount={5} // retry 5 times","mixwithothers#mixWithOthers":"Controls how Audio mix with other apps.\n\"inherit\" (default) - Use the default AVPlayer behavior\n\"mix\" - Audio from this video mixes with audio from other apps.\n\"duck\" - Reduces the volume of other apps while audio from this video plays.","muted#muted":"Controls whether the audio is muted\nfalse (default) - Don't mute audio\ntrue - Mute audio","paused#paused":"Controls whether the media is paused\nfalse (default) - Don't pause the media\ntrue - Pause the media","pictureinpicture#pictureInPicture":"Determine whether the media should played as picture in picture.\nfalse (default) - Don't not play as picture in picture\ntrue - Play the media as picture in picture\nNOTE: Video ads cannot start when you are using the PIP on iOS (more info available at Google IMA SDK Docs). If you are using custom controls, you must hide your PIP button when you receive the STARTED event from onReceiveAdEvent and show it again when you receive the ALL_ADS_COMPLETED event.","playinbackground#playInBackground":"Determine whether the media should continue playing while the app is in the background. This allows customers to continue listening to the audio.\nfalse (default) - Don't continue playing the media\ntrue - Continue playing the media\nTo use this feature on iOS, you must:\nEnable Background Audio in your Xcode project\nSet the ignoreSilentSwitch prop to \"ignore\"","playwheninactive#playWhenInactive":"Determine whether the media should continue playing when notifications or the Control Center are in front of the video.\nfalse (default) - Don't continue playing the media\ntrue - Continue playing the media","poster#poster":"An image to display while the video is loadingValue: string with a URL for the poster, e.g. \"https://baconmockup.com/300/200/\"","posterresizemode#posterResizeMode":"Determines how to resize the poster image when the frame doesn't match the raw video dimensions.\n\"contain\" (default) - Scale the image uniformly (maintain the image's aspect ratio) so that both dimensions (width and height) of the image will be equal to or less than the corresponding dimension of the view (minus padding).\n\"center\" - Center the image in the view along both dimensions. If the image is larger than the view, scale it down uniformly so that it is contained in the view.\n\"cover\" - Scale the image uniformly (maintain the image's aspect ratio) so that both dimensions (width and height) of the image will be equal to or larger than the corresponding dimension of the view (minus padding).\n\"none\" - Don't apply resize\n\"repeat\" - Repeat the image to cover the frame of the view. The image will keep its size and aspect ratio. (iOS only)\n\"stretch\" - Scale width and height independently, This may change the aspect ratio of the src.","preferredforwardbufferduration#preferredForwardBufferDuration":"The duration the player should buffer media from the network ahead of the playhead to guard against playback disruption. Sets the preferredForwardBufferDuration instance property on AVPlayerItem.Default: 0","preventsdisplaysleepduringvideoplayback#preventsDisplaySleepDuringVideoPlayback":"Controls whether or not the display should be allowed to sleep while playing the video. Default is not to allow display to sleep.Default: true","progressupdateinterval#progressUpdateInterval":"Delay in milliseconds between onProgress events in milliseconds.Default: 250.0","rate#rate":"Speed at which the media should play.\n0.0 - Pauses the video (iOS only)\n1.0 - Play at normal speed (default)\nOther values - Slow down or speed up playback","repeat#repeat":"Determine whether to repeat the video when the end is reached\nfalse (default) - Don't repeat the video\ntrue - Repeat the video","onaudiotracks#onAudioTracks":"Callback function that is called when audio tracks changePayload:\nProperty\tType\tDescription\tindex\tnumber\tInternal track ID\ttitle\tstring\tDescriptive name for the track\tlanguage\tstring\t2 letter ISO 639-1 code representing the language\tbitrate\tnumber\tbitrate of track\ttype\tstring\tMime type of track\tselected\tboolean\ttrue if track is playing\t\nExample:\n{\n  audioTracks: [\n    { language: 'es', title: 'Spanish', type: 'audio/mpeg', index: 0, selected: true },\n    { language: 'en', title: 'English', type: 'audio/mpeg', index: 1 }\n  ],\n}","reportbandwidth#reportBandwidth":"Determine whether to generate onBandwidthUpdate events. This is needed due to the high frequency of these events on ExoPlayer.\nfalse (default) - Don't generate onBandwidthUpdate events\ntrue - Generate onBandwidthUpdate events","resizemode#resizeMode":"Determines how to resize the video when the frame doesn't match the raw video dimensions.\n\"none\" (default) - Don't apply resize\n\"contain\" - Scale the video uniformly (maintain the video's aspect ratio) so that both dimensions (width and height) of the video will be equal to or less than the corresponding dimension of the view (minus padding).\n\"cover\" - Scale the video uniformly (maintain the video's aspect ratio) so that both dimensions (width and height) of the image will be equal to or larger than the corresponding dimension of the view (minus padding).\n\"stretch\" - Scale width and height independently, This may change the aspect ratio of the src.","selectedaudiotrack#selectedAudioTrack":"Configure which audio track, if any, is played.\nselectedAudioTrack={{\n  type: Type,\n  value: Value\n}}\nExample:\nselectedAudioTrack={{\n  type: \"title\",\n  value: \"Dubbing\"\n}}\nType\tValue\tDescription\t\"system\" (default)\tN/A\tPlay the audio track that matches the system language. If none match, play the first track.\t\"disabled\"\tN/A\tTurn off audio\t\"title\"\tstring\tPlay the audio track with the title specified as the Value, e.g. \"French\"\t\"language\"\tstring\tPlay the audio track with the language specified as the Value, e.g. \"fr\"\t\"index\"\tnumber\tPlay the audio track with the index specified as the value, e.g. 0\t\nIf a track matching the specified Type (and Value if appropriate) is unavailable, the first audio track will be played. If multiple tracks match the criteria, the first match will be used.","selectedtexttrack#selectedTextTrack":"Configure which text track (caption or subtitle), if any, is shown.\nselectedTextTrack={{\n  type: Type,\n  value: Value\n}}\nExample:\nselectedTextTrack={{\n  type: \"title\",\n  value: \"English Subtitles\"\n}}\nType\tValue\tDescription\t\"system\" (default)\tN/A\tDisplay captions only if the system preference for captions is enabled\t\"disabled\"\tN/A\tDon't display a text track\t\"title\"\tstring\tDisplay the text track with the title specified as the Value, e.g. \"French 1\"\t\"language\"\tstring\tDisplay the text track with the language specified as the Value, e.g. \"fr\"\t\"index\"\tnumber\tDisplay the text track with the index specified as the value, e.g. 0\t\nBoth iOS & Android (only 4.4 and higher) offer Settings to enable Captions for hearing impaired people. If \"system\" is selected and the Captions Setting is enabled, iOS/Android will look for a caption that matches that customer's language and display it.If a track matching the specified Type (and Value if appropriate) is unavailable, no text track will be displayed. If multiple tracks match the criteria, the first match will be used.","selectedvideotrack#selectedVideoTrack":"Configure which video track should be played. By default, the player uses Adaptive Bitrate Streaming to automatically select the stream it thinks will perform best based on available bandwidth.\nselectedVideoTrack={{\n  type: Type,\n  value: Value\n}}\nExample:\nselectedVideoTrack={{\n  type: \"resolution\",\n  value: 480\n}}\nType\tValue\tDescription\t\"auto\" (default)\tN/A\tLet the player determine which track to play using ABR\t\"disabled\"\tN/A\tTurn off video\t\"resolution\"\tnumber\tPlay the video track with the height specified, e.g. 480 for the 480p stream\t\"index\"\tnumber\tPlay the video track with the index specified as the value, e.g. 0\t\nIf a track matching the specified Type (and Value if appropriate) is unavailable, ABR will be used.","shuttercolor#shutterColor":"Apply color to shutter view, if you see black flashes before video start then set\nshutterColor = 'transparent';\nblack (default)","source#source":"Sets the media source. You can pass an asset loaded via require or an object with a uri.Setting the source will trigger the player to attempt to load the provided media with all other given props. Please be sure that all props are provided before/at the same time as setting the source.Rendering the player component with a null source will init the player, and start playing once a source value is provided.Providing a null source value after loading a previous source will stop playback, and clear out the previous source content.The docs for this prop are incomplete and will be updated as each option is investigated and tested.","asset-loaded-via-require#Asset loaded via require":"⚠️ on iOS, you file name must not contain spaces eg. my video.mp4 will not work, use my-video.mp4 instead\nExample:Pass directly the asset to play (deprecated)\nconst sintel = require('./sintel.mp4');\nsource={ sintel };\nOr by using an uri (starting from 6.0.0-beta.6)\nconst sintel = require('./sintel.mp4');\nsource={{ uri: sintel }}","uri-string#URI string":"A number of URI schemes are supported by passing an object with a uri attribute.All uri string shall be url encoded.\nFor exemple 'www.myurl.com/blabla?q=test uri' is invalid, where 'www.myurl.com/blabla?q=test%20uri' is valid","web-address-http-https#Web address (http://, https://)":"Example:\nsource={{uri: 'https://www.sample-videos.com/video/mp4/720/big_buck_bunny_720p_10mb.mp4' }}","file-path-file#File path (file://)":"Example:\nsource={{ uri: 'file:///sdcard/Movies/sintel.mp4' }}\nNote: Your app will need to request permission to read external storage if you're accessing a file outside your app.","ipod-library-ipod-library#iPod Library (ipod-library://)":"Path to a sound file in your iTunes library. Typically shared from iTunes to your app.Example:\nsource={{ uri: 'ipod-library:///path/to/music.mp3' }}\nNote: Using this feature adding an entry for NSAppleMusicUsageDescription to your Info.plist file as described here","explicit-mimetype-for-the-stream#Explicit mimetype for the stream":"Provide a member type with value (mpd/m3u8/ism) inside the source object.\nSometimes is needed when URL extension does not match with the mimetype that you are expecting, as seen on the next example. (Extension is .ism -smooth streaming- but file served is on format mpd -mpeg dash-)Example:\nsource={{ uri: 'http://host-serving-a-type-different-than-the-extension.ism/manifest(format=mpd-time-csf)',\ntype: 'mpd' }}","other-protocols#Other protocols":"The following other types are supported on some platforms, but aren't fully documented yet:\ncontent://, ms-appx://, ms-appdata://, assets-library://","start-playback-at-a-specific-point-in-time#Start playback at a specific point in time":"Provide an optional startPosition for video. Value is in milliseconds. If the cropStart prop is applied, it will be applied from that point forward.\n(If it is negative or undefined or null, it is ignored)","playing-only-a-portion-of-the-video-start--end-time#Playing only a portion of the video (start & end time)":"Provide an optional cropStart and/or cropEnd for the video. Value is in milliseconds. Useful when you want to play only a portion of a large video.Example\nsource={{ uri: 'https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8', cropStart: 36012, cropEnd: 48500 }}\nsource={{ uri: 'https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8', cropStart: 36012 }}\nsource={{ uri: 'https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8', cropEnd: 48500 }}","overriding-the-metadata-of-a-source#Overriding the metadata of a source":"Provide an optional title, subtitle, customImageUri and/or description properties for the video.\nUseful when to adapt the tvOS playback experience.Example:\nsource={{\n    uri: 'https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8',\n    title: 'Custom Title',\n    subtitle: 'Custom Subtitle',\n    description: 'Custom Description',\n    customImageUri: 'https://pbs.twimg.com/profile_images/1498641868397191170/6qW2XkuI_400x400.png'\n  }}","subtitlestyle#subtitleStyle":"Property\tDescription\tPlatforms\tfontSize\tAdjust the font size of the subtitles. Default: font size of the device\tAndroid\tpaddingTop\tAdjust the top padding of the subtitles. Default: 0\tAndroid\tpaddingBottom\tAdjust the bottom padding of the subtitles. Default: 0\tAndroid\tpaddingLeft\tAdjust the left padding of the subtitles. Default: 0\tAndroid\tpaddingRight\tAdjust the right padding of the subtitles. Default: 0\tAndroid\topacity\tAdjust the visibility of subtitles with 0 hiding and 1 fully showing them. Android supports float values between 0 and 1 for varying opacity levels, whereas iOS supports only 0 or 1. Default: 1.\tAndroid, iOS\t\nExample:\nsubtitleStyle={{ paddingBottom: 50, fontSize: 20, opacity: 0 }}","texttracks#textTracks":"Load one or more \"sidecar\" text tracks. This takes an array of objects representing each track. Each object should have the format:\n⚠️ This feature does not work with HLS playlists (e.g m3u8) on iOS\nProperty\tDescription\ttitle\tDescriptive name for the track\tlanguage\t2 letter ISO 639-1 code representing the language\ttype\tMime type of the track _ TextTrackType.SRT - SubRip (.srt) _ TextTrackType.TTML - TTML (.ttml) * TextTrackType.VTT - WebVTT (.vtt)iOS only supports VTT, Android supports all 3\turi\tURL for the text track. Currently, only tracks hosted on a webserver are supported\t\nOn iOS, sidecar text tracks are only supported for individual files, not HLS playlists. For HLS, you should include the text tracks as part of the playlist.Note: Due to iOS limitations, sidecar text tracks are not compatible with Airplay. If textTracks are specified, AirPlay support will be automatically disabled.Example:\nimport { TextTrackType }, Video from 'react-native-video';\ntextTracks={[\n  {\n    title: \"English CC\",\n    language: \"en\",\n    type: TextTrackType.VTT, // \"text/vtt\"\n    uri: \"https://bitdash-a.akamaihd.net/content/sintel/subtitles/subtitles_en.vtt\"\n  },\n  {\n    title: \"Spanish Subtitles\",\n    language: \"es\",\n    type: TextTrackType.SRT, // \"application/x-subrip\"\n    uri: \"https://durian.blender.org/wp-content/content/subtitles/sintel_es.srt\"\n  }\n]}","trackid#trackId":"Configure an identifier for the video stream to link the playback context to the events emitted.","usetextureview#useTextureView":"Controls whether to output to a TextureView or SurfaceView.SurfaceView is more efficient and provides better performance but has two limitations:\nIt can't be animated, transformed or scaled\nYou can't overlay multiple SurfaceViews\nuseTextureView can only be set at same time you're setting the source.\ntrue (default) - Use a TextureView\nfalse - Use a SurfaceView","usesecureview#useSecureView":"Force the output to a SurfaceView and enables the secure surface.This will override useTextureView flag.SurfaceView is is the only one that can be labeled as secure.\ntrue - Use security\nfalse (default) - Do not use security","volume#volume":"Adjust the volume.\n1.0 (default) - Play at full volume\n0.0 - Mute the audio\nOther values - Reduce volume","localsourceencryptionkeyscheme#localSourceEncryptionKeyScheme":"Set the url scheme for stream encryption key for local assetsType: StringExample:\nlocalSourceEncryptionKeyScheme=\"my-offline-key\""}},"/":{"title":"A <Video> component for React Native","data":{"about#About":"react-native-video is a React Native library that provides a Video component that renders media content such as videos and streams","beta-information#Beta Information":"⚠️ Version 6 Beta: The following documentation may refer to features only available through the v6.0.0 alpha releases, please see version 5.2.x for the current documentation!\nVersion 6.x recommends react-native >= 0.68.2.For older versions of react-native, please use version 5.x.","usage#Usage":"// Load the module\nimport Video, {VideoRef} from 'react-native-video';\n// Within your render function, assuming you have a file called\n// \"background.mp4\" in your project. You can include multiple videos\n// on a single screen if you like.\nconst VideoPlayer = () => {\n const videoRef = useRef<VideoRef>(null);\n const background = require('./background.mp4');\n return (\n   <Video \n    // Can be a URL or a local file.\n    source={background}\n    // Store reference  \n    ref={videoRef}\n    // Callback when remote video is buffering                                      \n    onBuffer={onBuffer}\n    // Callback when video cannot be loaded              \n    onError={onError}               \n    style={styles.backgroundVideo}\n   />\n )\n}\n// Later on in your styles..\nvar styles = StyleSheet.create({\n  backgroundVideo: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n    bottom: 0,\n    right: 0,\n  },\n});","version-600-breaking-changes#Version 6.0.0 breaking changes":"Version 6.0.0 is introducing dozens of breaking changes, mostly through updated dependencies and significant refactoring. While the API remains compatible, the significant internal changes require full testing with your app to ensure all functionality remains operational. Please view the Changelog for specific breaking changes.","installing-version-600-beta#Installing Version 6.0.0 Beta":"Whilst we finalise version 6.0.0 you can install the latest beta from npmUsing npm:\nnpm install --save react-native-video@beta\nusing yarn:\nyarn add react-native-video@beta"}},"/installation":{"title":"Installation","data":{"":"Using npm:\nnpm install --save react-native-video\nor using yarn:\nyarn add react-native-video\nThen follow the instructions for your platform to link react-native-video into your project","ios#iOS":"","standard-method#Standard Method":"","enable-custom-feature-in-podfile-file#Enable custom feature in podfile file":"Samples available in sample app see sample pod file","video-caching#Video caching":"To enable Video caching usage, add following line in your podfile:\n(more info here)\n# enable Video caching\n+ $RNVideoUseVideoCaching=true","google-ima#Google IMA":"Google IMA is the google SDK to support Client Side Ads Integration (CSAI), see google documentation for more information.To enable google IMA usage define add following line in your podfile:\n$RNVideoUseGoogleIMA=true","android#Android":"From version >= 6.0.0, your application needs to have kotlin version >= 1.7.0\nbuildscript {\n    ...\n    ext.kotlinVersion = '1.7.0'\n    ...\n}","enable-custom-feature-in-gradle-file#Enable custom feature in gradle file":"","enable-client-side-ads-insertion#Enable client side ads insertion":"To enable client side ads insertion CSAI with google IMA SDK, you need to enable it in your gradle file.\nbuildscript {\n  ext {\n    ...\n    RNVUseExoplayerIMA = true\n    ...\n  }\n}\nSee sample app","windows#Windows":"","autolinking#Autolinking":"React Native Windows 0.63 and aboveAutolinking should automatically add react-native-video to your app.","manual-linking#Manual Linking":"React Native Windows 0.62Make the following additions to the given files manually:windows\\myapp.slnAdd the ReactNativeVideoCPP project to your solution (eg. windows\\myapp.sln):\nOpen your solution in Visual Studio 2019\nRight-click Solution icon in Solution Explorer > Add > Existing Project...\nSelect node_modules\\react-native-video\\windows\\ReactNativeVideoCPP\\ReactNativeVideoCPP.vcxproj\nwindows\\myapp\\myapp.vcxprojAdd a reference to ReactNativeVideoCPP to your main application project (eg. windows\\myapp\\myapp.vcxproj):\nOpen your solution in Visual Studio 2019\nRight-click main application project > Add > Reference...\nCheck ReactNativeVideoCPP from Solution Projects\npch.hAdd #include \"winrt/ReactNativeVideoCPP.h\".app.cppAdd PackageProviders().Append(winrt::ReactNativeVideoCPP::ReactPackageProvider()); before InitializeComponent();.React Native Windows 0.61 and belowFollow the manual linking instructions for React Native Windows 0.62 above, but substitute ReactNativeVideoCPP61 for ReactNativeVideoCPP.","tvos#tvOS":"react-native link react-native-video doesn’t work properly with the tvOS target so we need to add the library manually.First select your project in Xcode.After that, select the tvOS target of your application and select « General » tabScroll to « Linked Frameworks and Libraries » and tap on the + buttonSelect RCTVideo-tvOS","visionos#visionOS":"Add patch for promises pods to your pod files to make it work with visionOS target.\nThis patch is required only for visionOS target and will be removed in future.\n+ pod 'PromisesSwift', :podspec => '../node_modules/react-native-video/ios/patches/PromisesSwift.podspec'\n+ pod 'PromisesObjC', :podspec => '../node_modules/react-native-video/ios/patches/PromisesObjC.podspec'\nRemember to run pod install after adding this patch.After this you can follow the same steps as for iOS target.","examples#Examples":"Run yarn xbasic install in the root directory before running any of the examples.","ios-example#iOS Example":"yarn xbasic ios","android-example#Android Example":"yarn xbasic android","windows-example#Windows Example":"yarn xbasic windows"}},"/other/caching":{"title":"Caching","data":{"":"Caching is currently only supported on iOS platforms with a CocoaPods setup.","technology#Technology":"The cache is backed by SPTPersistentCache and DVAssetLoaderDelegate.","how-does-it-work#How Does It Work":"The caching is based on the url of the asset.\nSPTPersistentCache is a LRU (Least Recently Used) cache.","restrictions#Restrictions":"Currently, caching is only supported for URLs that end in a .mp4, .m4v, or .mov extension. In future versions, URLs that end in a query string (e.g. test.mp4?resolution=480p) will be support once dependencies allow access to the Content-Type header.  At this time, HLS playlists (.m3u8) and videos that sideload text tracks are not supported and will bypass the cache.You will also receive warnings in the Xcode logs by using the debug mode. So if you are not 100% sure if your video is cached, check your Xcode logs!By default files expire after 30 days and the maximum cache size is 100mb.In a future release the cache might have more configurable options."}},"/other/debug":{"title":"Debugging","data":{"http-playback-doesnt-work-or--black-screen-on-release-build-android#HTTP playback doesn't work or  Black Screen on Release build (Android)":"If your video work on Debug mode, but on Release you see only black screen, please, check the link to your video. If you use 'http' protocol there, you will need to add next string to your AndroidManifest.xml file. Details here\n<application\n ...\n android:usesCleartextTraffic=\"true\"\n>","decoder-issue-android#Decoder Issue (Android)":"Devices have a maximum of simultaneous possible playback. It means you have reach this limit. Exoplayer returns: 'Unable to instantiate decoder'known issue: This issue happen really often in debug mode.","you-cannot-play-clean-content-all-os#You cannot play clean content (all OS)":"Here are the steps to consider before opening a ticket in issue tracker","check-you-can-access-to-remote-file#Check you can access to remote file":"Ensure you can download to manifest / content file with a browser for example","check-another-player-can-read-the-content#Check another player can read the content":"Usually clear playback can be read with all Video player. Then you should ensure content can be played without any issue with another player (VideoLan/VLC is a good reference implementation)","you-cannot-play-protected-content-all-os#You cannot play protected content (all OS)":"","protected-content-gives-error-token-error--access-forbidden#Protected content gives error (token error / access forbidden)":"If content is protected with an access token or any other http header, ensure you can access to you data with a wget call or a rest client app. You need to provide all needed access token / authentication parameters.","everything-seems-correct-but-content-cannot-be-accessed#Everything seems correct but content cannot be accessed":"You need to record network trace to ensure communications with server is correct.\nCharles proxy is a simple and useful tool to sniff all http/https calls.\nWith this tool you should be able to analyze what is going on with network. You will see all access to content and DRM, audio / video chunks, ...Then try to compare exchanges with previous tests you made.","its-still-not-working#It's still not working":"You can try to open a ticket now !"}},"/other/misc":{"title":"Miscellaneous","data":{"ios-app-transport-security#iOS App Transport Security":"By default, iOS will only load encrypted (https) urls. If you want to load content from an unencrypted (http) source, you will need to modify your Info.plist file and add the following entry:\nFor more detailed info check this article","audio-mixing#Audio Mixing":"At some point in the future, react-native-video will include an Audio Manager for configuring how videos mix with other apps playing sounds on the device.On iOS, if you would like to allow other apps to play music over your video component, make the following change:AppDelegate.m\n#import <AVFoundation/AVFoundation.h>  // import\n- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions\n{\n  ...\n  [[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategoryAmbient error:nil];  // allow\n  ...\n}\nYou can also use the ignoreSilentSwitch prop.","android-expansion-file-usage#Android Expansion File Usage":"Expansions files allow you to ship assets that exceed the 100MB apk size limit and don't need to be updated each time you push an app update.This only supports mp4 files and they must not be compressed. Example command line for preventing compression:\nzip -r -n .mp4 *.mp4 player.video.example.com\n// Within your render function, assuming you have a file called\n// \"background.mp4\" in your expansion file. Just add your main and (if applicable) patch version\n<Video source={{uri: \"background\", mainVer: 1, patchVer: 0}} // Looks for .mp4 file (background.mp4) in the given expansion version.\n       resizeMode=\"cover\"           // Fill the whole screen at aspect ratio.\n       style={styles.backgroundVideo} />","load-files-with-the-rn-asset-system#Load files with the RN Asset System":"The asset system introduced in RN 0.14 allows loading image resources shared across iOS and Android without touching native code. As of RN 0.31 the same is true of mp4 video assets for Android. As of RN 0.33 iOS is also supported. Requires react-native-video@0.9.0.\n<Video\n  source={require('../assets/video/turntable.mp4')}\n/>","play-in-background-on-ios#Play in background on iOS":"To enable audio to play in background on iOS the audio session needs to be set to AVAudioSessionCategoryPlayback. See [Apple documentation][3] for additional details. (NOTE: there is now a ticket to expose this as a prop )","examples#Examples":"See an [Example integration][1] in react-native-login note that this example uses an older version of this library, before we used export default -- if you use require you will need to do require('react-native-video').default as per instructions above.\nTry the included [VideoPlayer example][2] yourself:\ngit clone git@github.com:react-native-community/react-native-video.git\ncd react-native-video/example\nnpm install\nopen ios/VideoPlayer.xcodeproj\nThen Cmd+R to start the React Packager, build and run the project in the simulator.\nLumpen Radio contains another example integration using local files and full screen background video."}},"/other/new-arch":{"title":"New Architecture","data":{"fabric#Fabric":"Library currently does not support Fabric. We are working on it. In the meantime, you can use Interop Layer.","interop-layer#Interop Layer":"You can use this library on New Architecture by using Interop Layer.  To use Interop Layer you need to have react-native >= 0.72.0 & react-native-video >= 6.0.0-beta.5.For react-native < 0.74 you need to add config in react-native.config.js file.\nmodule.exports = {\n  project: {\n    android: {\n      unstable_reactLegacyComponentNames: ['Video'],\n    },\n    ios: {\n      unstable_reactLegacyComponentNames: ['Video'],\n    },\n  },\n};","bridgeless-mode#Bridgeless Mode":"Library currently does not support Bridgeless Mode. We are working on it."}},"/projects":{"title":"Useful projects","data":{"":"This page links other open source projects which can be useful for your player implementation. \nIf you have a project which can be useful for other users, feel free to open a PR to add it here.","ui-over-react-native-video#UI over react-native-video":"react-native-video-controls: First reference player UI\nreact-native-media-console: React-native-video-controls updated and rewritten in typescript\nreact-native-corner-video: A floating video player","other-tools#Other tools":"react-native-music-control: A toolbox to control player over media session"}},"/updating":{"title":"Updating","data":{"version-600#Version 6.0.0":"","ios#iOS":"","linking#linking":"In your project Podfile add support for static dependency linking. This is required to support the new Promises subdependency in the iOS swift conversion.Add use_frameworks! :linkage => :static just under platform :ios in your ios project Podfile.See the example ios project for reference","podspec#podspec":"You can remove following lines from your podfile as they are not necessary anymore\n-  `pod 'react-native-video', :path => '../node_modules/react-native-video/react-native-video.podspec'`\n-  `pod 'react-native-video/VideoCaching', :path => '../node_modules/react-native-video/react-native-video.podspec'`\nIf you were previously using VideoCaching, you should $RNVideoUseVideoCaching flag in your podspec, see: installation section","android#Android":"If you are already using Exoplayer on V5, you should remove the patch done from android/settings.gradle\n- include ':react-native-video'\n- project(':react-native-video').projectDir = new File(rootProject.projectDir, '../node_modules/react-native-video/android-exoplayer')","using-app-build-settings#Using app build settings":"You will need to create a project.ext section in the top-level build.gradle file (not app/build.gradle). Fill in the values from the example below using the values found in your app/build.gradle file.\n// Top-level build file where you can add configuration options common to all sub-projects/modules.\nbuildscript {\n    ... // Various other settings go here\n}\nallprojects {\n    ... // Various other settings go here\n    project.ext {\n        compileSdkVersion = 31\n        buildToolsVersion = \"30.0.2\"\n        minSdkVersion = 21\n        targetSdkVersion = 22\n    }\n}\nIf you encounter an error Could not find com.android.support:support-annotations:27.0.0. reinstall your Android Support Repository."}}}